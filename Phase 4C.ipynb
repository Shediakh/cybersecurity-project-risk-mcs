{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e2d8f5b-831c-4f29-919b-cc5f64944e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9777a82f-0cd1-4440-84e8-898a7da8e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA = \"ml_outputs/ml_dataset.csv\"\n",
    "df = pd.read_csv(DATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cf472fc-cb8c-46c6-81da-e47c9f59aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Labels: high-risk projects (decision-oriented)\n",
    "df[\"y_high_cost_overrun\"] = (df[\"p_cost_over_cpm\"] >= df[\"p_cost_over_cpm\"].quantile(0.75)).astype(int)\n",
    "df[\"y_high_sched_overrun\"] = (df[\"p_duration_over_cpm\"] >= df[\"p_duration_over_cpm\"].quantile(0.75)).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b0ddfe1-e783-4766-9d0d-9cc33e549d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical = [\"size_bucket\", \"risk_level_bucket\", \"late_concentration\", \"tail_type\", \"coupling\"]\n",
    "numeric_base = [\"n_tasks\", \"n_streams\", \"burn_rate_per_day\", \"fixed_cost\",\n",
    "                \"risk_prob_sum\", \"late_risk_prob_sum\", \"avg_prob\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba8b2798-718f-47d2-bb6e-57772bcf6a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint-only features from risk register expectations (non-leaky)\n",
    "coupling_feats = [\n",
    "    \"E_sched_add_total\", \"E_cost_lump_total\", \"E_mul_excess_total\",\n",
    "    \"late_E_sched_add\", \"late_E_cost_lump\",\n",
    "    \"risk_cost_per_day\", \"late_risk_share_cost\", \"late_risk_share_sched\",\n",
    "    \"expected_delay_ratio\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67380035-d5f1-4890-b8c0-24e31440e9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_only = categorical + numeric_base + [\"cpm_cost\"]\n",
    "schedule_only = categorical + numeric_base + [\"cpm_duration\"]\n",
    "joint = categorical + numeric_base + [\"cpm_cost\", \"cpm_duration\"] + coupling_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe7348b9-22e8-4f46-aa4b-0d73cb993058",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loo_classification(Xcols, ycol, estimator):\n",
    "    X = df[Xcols]\n",
    "    y = df[ycol].values\n",
    "\n",
    "    loo = LeaveOneOut()\n",
    "    probs = np.zeros_like(y, dtype=float)\n",
    "    preds = np.zeros_like(y, dtype=int)\n",
    "\n",
    "    for tr, te in loo.split(X):\n",
    "        Xtr, Xte = X.iloc[tr], X.iloc[te]\n",
    "        ytr = y[tr]\n",
    "\n",
    "        pre = ColumnTransformer([\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical),\n",
    "            (\"num\", StandardScaler(), [c for c in Xcols if c not in categorical]),\n",
    "        ])\n",
    "\n",
    "\n",
    "        pipe = Pipeline([\n",
    "            (\"pre\", pre),\n",
    "            (\"m\", clone(estimator))\n",
    "        ])\n",
    "\n",
    "        pipe.fit(Xtr, ytr)\n",
    "\n",
    "        # Some classifiers expose predict_proba, others decision_function\n",
    "        if hasattr(pipe.named_steps[\"m\"], \"predict_proba\"):\n",
    "            p = pipe.predict_proba(Xte)[0, 1]\n",
    "        else:\n",
    "            # convert decision score to probability-ish via sigmoid\n",
    "            s = pipe.decision_function(Xte)[0]\n",
    "            p = 1.0 / (1.0 + np.exp(-s))\n",
    "\n",
    "        probs[te[0]] = p\n",
    "        preds[te[0]] = int(p >= 0.5)\n",
    "\n",
    "    auc = roc_auc_score(y, probs) if len(np.unique(y)) == 2 else np.nan\n",
    "    f1 = f1_score(y, preds, zero_division=0)\n",
    "    acc = accuracy_score(y, preds)\n",
    "    return auc, f1, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d93f893-c1f2-4325-b8ea-1d65d8047dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"LogReg\", LogisticRegression(max_iter=5000)),\n",
    "    (\"RF\", RandomForestClassifier(n_estimators=400, random_state=0))\n",
    "]\n",
    "\n",
    "experiments = [\n",
    "    (\"High Cost Overrun\", \"y_high_cost_overrun\"),\n",
    "    (\"High Schedule Overrun\", \"y_high_sched_overrun\")\n",
    "]\n",
    "\n",
    "feature_sets = [\n",
    "    (\"Cost-only\", cost_only),\n",
    "    (\"Schedule-only\", schedule_only),\n",
    "    (\"Joint\", joint)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9949e2b-5e4d-4481-b3e9-c6eb624f6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- run models ----\n",
    "rows = []\n",
    "for exp_name, ycol in experiments:\n",
    "    for fs_name, feats in feature_sets:\n",
    "        for mname, est in models:\n",
    "            auc, f1, acc = loo_classification(feats, ycol, est)\n",
    "            rows.append({\n",
    "                \"experiment\": exp_name,\n",
    "                \"features\": fs_name,\n",
    "                \"model\": mname,\n",
    "                \"ROC_AUC\": auc,\n",
    "                \"F1\": f1,\n",
    "                \"Accuracy\": acc\n",
    "            })\n",
    "\n",
    "res = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d95e1da9-59d2-4097-8128-a245133332bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- add baseline ----\n",
    "baseline_rows = []\n",
    "for exp_name, ycol in experiments:\n",
    "    y = df[ycol].values\n",
    "    baseline_acc = max(y.mean(), 1 - y.mean())\n",
    "    baseline_rows.append({\n",
    "        \"experiment\": exp_name,\n",
    "        \"features\": \"Baseline\",\n",
    "        \"model\": \"Always-majority\",\n",
    "        \"ROC_AUC\": np.nan,\n",
    "        \"F1\": np.nan,\n",
    "        \"Accuracy\": baseline_acc\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bd3d3ab-fc3a-4137-bd5e-2a966bd6a295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               experiment       features            model   ROC_AUC        F1  \\\n",
      "5       High Cost Overrun          Joint               RF  0.694444  0.200000   \n",
      "4       High Cost Overrun          Joint           LogReg  0.675926  0.500000   \n",
      "1       High Cost Overrun      Cost-only               RF  0.643519  0.181818   \n",
      "0       High Cost Overrun      Cost-only           LogReg  0.629630  0.333333   \n",
      "2       High Cost Overrun  Schedule-only           LogReg  0.629630  0.333333   \n",
      "3       High Cost Overrun  Schedule-only               RF  0.615741  0.200000   \n",
      "12      High Cost Overrun       Baseline  Always-majority       NaN       NaN   \n",
      "9   High Schedule Overrun  Schedule-only               RF  0.805556  0.181818   \n",
      "10  High Schedule Overrun          Joint           LogReg  0.805556  0.500000   \n",
      "11  High Schedule Overrun          Joint               RF  0.805556  0.200000   \n",
      "8   High Schedule Overrun  Schedule-only           LogReg  0.787037  0.363636   \n",
      "7   High Schedule Overrun      Cost-only               RF  0.782407  0.181818   \n",
      "6   High Schedule Overrun      Cost-only           LogReg  0.768519  0.200000   \n",
      "13  High Schedule Overrun       Baseline  Always-majority       NaN       NaN   \n",
      "\n",
      "    Accuracy  \n",
      "5   0.666667  \n",
      "4   0.750000  \n",
      "1   0.625000  \n",
      "0   0.666667  \n",
      "2   0.666667  \n",
      "3   0.666667  \n",
      "12  0.750000  \n",
      "9   0.625000  \n",
      "10  0.750000  \n",
      "11  0.666667  \n",
      "8   0.708333  \n",
      "7   0.625000  \n",
      "6   0.666667  \n",
      "13  0.750000  \n"
     ]
    }
   ],
   "source": [
    "res = pd.concat([res, pd.DataFrame(baseline_rows)], ignore_index=True)\n",
    "res = res.sort_values([\"experiment\",\"ROC_AUC\"], ascending=[True, False])\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af951be6-646d-4e39-b892-85cbea3c98df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: ml_outputs/classification_results.csv\n",
      "\n",
      "Label balance:\n",
      "y_high_cost_overrun     0.25\n",
      "y_high_sched_overrun    0.25\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "res.to_csv(\"ml_outputs/classification_results.csv\", index=False)\n",
    "print(\"\\nSaved: ml_outputs/classification_results.csv\")\n",
    "print(\"\\nLabel balance:\")\n",
    "print(df[[\"y_high_cost_overrun\",\"y_high_sched_overrun\"]].mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Environment1]",
   "language": "python",
   "name": "conda-env-Environment1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
