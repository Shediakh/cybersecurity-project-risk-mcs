{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5459592-bdf0-4163-8646-e8e5ae93070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f27ed31-54cd-41d4-9bbc-e744bd5beaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# Configuration\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class GeneratorConfig:\n",
    "    n_projects: int = 24             # minimum 20; 24/30 is nicer for grouping\n",
    "    seed: int = 42\n",
    "    out_dir: str = \".\"\n",
    "    # templates control: you can tweak later\n",
    "    min_tasks: int = 14\n",
    "    max_tasks: int = 22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b85f541-b9ca-4c01-a430-48f6c9f0dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Project Template Builder\n",
    "# =========================\n",
    "\n",
    "# We use a \"phase DAG\" (requirements -> design -> build (parallel streams) -> test -> deploy)\n",
    "# Each project will have a different number of build streams and optional tasks.\n",
    "PHASES = [\n",
    "    \"INIT\",\n",
    "    \"REQ\",\n",
    "    \"DESIGN\",\n",
    "    \"GOV\",       # security governance / policy / compliance planning\n",
    "    \"BUILD_A\",   # parallel stream A\n",
    "    \"BUILD_B\",   # parallel stream B (optional)\n",
    "    \"BUILD_C\",   # parallel stream C (optional)\n",
    "    \"INTEGRATE\",\n",
    "    \"DOC\",\n",
    "    \"UAT\",\n",
    "    \"SEC_TEST\",  # pen test / security testing gate\n",
    "    \"REMEDIATE\",\n",
    "    \"PREPROD\",\n",
    "    \"PILOT\",\n",
    "    \"ROLLOUT\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba089350-a52d-4e8e-a126-dbdfc2248e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tasks are defined as (task_code, task_name, phase, base_duration_scale_weight)\n",
    "BASE_TASK_LIBRARY = [\n",
    "    (\"T_INIT\", \"Project Initiation\", \"INIT\", 1.0),\n",
    "    (\"T_REQ\", \"Requirements Gathering\", \"REQ\", 1.2),\n",
    "    (\"T_DES\", \"Solution Architecture & Design\", \"DESIGN\", 1.1),\n",
    "    (\"T_GOV\", \"Security Policy / Governance\", \"GOV\", 1.0),\n",
    "\n",
    "    (\"T_BA\", \"Core Implementation Stream A\", \"BUILD_A\", 2.0),\n",
    "    (\"T_BB\", \"Implementation Stream B\", \"BUILD_B\", 1.6),\n",
    "    (\"T_BC\", \"Implementation Stream C\", \"BUILD_C\", 1.4),\n",
    "\n",
    "    (\"T_INT\", \"Systems Integration\", \"INTEGRATE\", 1.3),\n",
    "    (\"T_DOC\", \"Compliance Documentation\", \"DOC\", 1.0),\n",
    "\n",
    "    (\"T_UAT\", \"User Acceptance Testing\", \"UAT\", 1.2),\n",
    "    (\"T_SEC\", \"Security Testing / Penetration Testing\", \"SEC_TEST\", 1.3),\n",
    "    (\"T_REM\", \"Vulnerability Remediation\", \"REMEDIATE\", 1.2),\n",
    "\n",
    "    (\"T_PRE\", \"Pre-Production Validation\", \"PREPROD\", 1.0),\n",
    "    (\"T_PIL\", \"Pilot Deployment\", \"PILOT\", 1.0),\n",
    "    (\"T_ROL\", \"Full Production Rollout\", \"ROLLOUT\", 0.9),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb925074-193c-44d5-aa00-6ac1e60f9ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core dependencies (DAG)\n",
    "# We will add/omit certain tasks depending on project size\n",
    "BASE_DEPS = {\n",
    "    \"T_INIT\": [],\n",
    "    \"T_REQ\": [\"T_INIT\"],\n",
    "    \"T_DES\": [\"T_REQ\"],\n",
    "    \"T_GOV\": [\"T_DES\"],\n",
    "\n",
    "    \"T_BA\": [\"T_DES\", \"T_GOV\"],\n",
    "    \"T_BB\": [\"T_DES\", \"T_GOV\"],\n",
    "    \"T_BC\": [\"T_DES\", \"T_GOV\"],\n",
    "\n",
    "    \"T_INT\": [],   # will be set based on included build streams\n",
    "    \"T_DOC\": [\"T_GOV\"],\n",
    "\n",
    "    \"T_UAT\": [],   # will depend on integration + doc\n",
    "    \"T_SEC\": [\"T_UAT\"],\n",
    "    \"T_REM\": [\"T_SEC\"],\n",
    "\n",
    "    \"T_PRE\": [\"T_REM\"],\n",
    "    \"T_PIL\": [\"T_PRE\"],\n",
    "    \"T_ROL\": [\"T_PIL\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eba6544-496d-4dcf-995d-944dd5aca6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Risk Model\n",
    "# =========================\n",
    "\n",
    "# We model risks as events with:\n",
    "# - probability p\n",
    "# - schedule impact: additive days on target tasks OR multiplicative factor on target tasks\n",
    "# - cost impact: lump sum + optional per-day uplift (kept simple for now)\n",
    "\n",
    "RISK_LIBRARY = [\n",
    "    # risk_id, name, type, timing_bias, base_p_low, base_p_med, base_p_high\n",
    "    (\"R_COMP\", \"Compliance Change (policy/regulatory)\", \"ADD\", \"EARLY\", 0.10, 0.25, 0.40),\n",
    "    (\"R_VEND\", \"Vendor / third-party integration delay\", \"ADD\", \"MID\",   0.15, 0.30, 0.45),\n",
    "    (\"R_VULN\", \"Critical vulnerability discovered late\", \"MUL\", \"LATE\",  0.08, 0.20, 0.35),\n",
    "    (\"R_INCI\", \"Pilot security incident / rollback\",     \"ADD\", \"LATE\",  0.05, 0.12, 0.22),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78688fe8-bd93-4823-b4fd-e2de30f76768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target tasks per risk\n",
    "RISK_TARGETS = {\n",
    "    \"R_COMP\": [\"T_GOV\", \"T_DOC\"],\n",
    "    \"R_VEND\": [\"T_INT\"],\n",
    "    \"R_VULN\": [\"T_BA\", \"T_INT\", \"T_SEC\", \"T_REM\"],   # rework spreads\n",
    "    \"R_INCI\": [\"T_PIL\", \"T_ROL\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a402a4-e554-4887-b8a2-e471304f39cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Utility Functions\n",
    "# =========================\n",
    "\n",
    "def rng_for(seed: int) -> np.random.Generator:\n",
    "    return np.random.default_rng(seed)\n",
    "\n",
    "def triangular_params_from_scale(\n",
    "    base_days: float,\n",
    "    uncertainty: float,\n",
    "    r: np.random.Generator\n",
    ") -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Generate (O, M, P) around base_days.\n",
    "    uncertainty in [0.15..0.60] controls spread.\n",
    "    \"\"\"\n",
    "    # Most-likely around base_days with a small random drift\n",
    "    m = max(1.0, base_days * r.uniform(0.90, 1.10))\n",
    "    spread = base_days * uncertainty\n",
    "    o = max(1.0, m - spread * r.uniform(0.7, 1.1))\n",
    "    p = max(m + 1.0, m + spread * r.uniform(0.7, 1.3))\n",
    "    # Ensure ordering\n",
    "    if not (o <= m <= p):\n",
    "        o, m, p = sorted([o, m, p])\n",
    "    return (round(o, 2), round(m, 2), round(p, 2))\n",
    "\n",
    "def pick_project_profile(i: int, r: np.random.Generator) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Creates controlled variety.\n",
    "    \"\"\"\n",
    "    # 4 buckets: low/med/high/extreme (tail-heavy)\n",
    "    bucket = [\"LOW\", \"MED\", \"HIGH\", \"EXTREME\"][i % 4]\n",
    "\n",
    "    # Size bucket\n",
    "    size = [\"SMALL\", \"MEDIUM\", \"LARGE\"][i % 3]\n",
    "\n",
    "    # Late-risk concentration: EXTREME tends to be late-heavy\n",
    "    if bucket == \"EXTREME\":\n",
    "        late_conc = \"LATE_HEAVY\"\n",
    "        tail = \"HEAVY_TAIL\"\n",
    "    else:\n",
    "        late_conc = r.choice([\"BALANCED\", \"LATE_HEAVY\"], p=[0.6, 0.4])\n",
    "        tail = r.choice([\"NORMAL_TAIL\", \"HEAVY_TAIL\"], p=[0.75, 0.25])\n",
    "\n",
    "    # Coupling: whether cost and schedule are strongly tied\n",
    "    coupling = r.choice([\"WEAK\", \"STRONG\"], p=[0.45, 0.55])\n",
    "\n",
    "    return {\n",
    "        \"risk_level\": bucket,\n",
    "        \"size\": size,\n",
    "        \"late_concentration\": late_conc,\n",
    "        \"tail\": tail,\n",
    "        \"coupling\": coupling,\n",
    "    }\n",
    "\n",
    "def included_streams(size: str, r: np.random.Generator) -> List[str]:\n",
    "    \"\"\"\n",
    "    Decide how many build streams.\n",
    "    Small: A only (sometimes A+B)\n",
    "    Medium: A+B (sometimes A+B+C)\n",
    "    Large: A+B+C\n",
    "    \"\"\"\n",
    "    if size == \"SMALL\":\n",
    "        return [\"T_BA\"] if r.random() < 0.7 else [\"T_BA\", \"T_BB\"]\n",
    "    if size == \"MEDIUM\":\n",
    "        return [\"T_BA\", \"T_BB\"] if r.random() < 0.7 else [\"T_BA\", \"T_BB\", \"T_BC\"]\n",
    "    return [\"T_BA\", \"T_BB\", \"T_BC\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5fd7417-02b7-4070-9931-232344c1c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Core Generator\n",
    "# =========================\n",
    "\n",
    "def generate_projects(cfg: GeneratorConfig) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    r = rng_for(cfg.seed)\n",
    "\n",
    "    projects_rows = []\n",
    "    tasks_rows = []\n",
    "    risks_rows = []\n",
    "\n",
    "    for i in range(cfg.n_projects):\n",
    "        project_id = f\"P{i+1:02d}\"\n",
    "        profile = pick_project_profile(i, r)\n",
    "\n",
    "        # Baseline scale by size (days)\n",
    "        size = profile[\"size\"]\n",
    "        if size == \"SMALL\":\n",
    "            base_scale = r.uniform(0.7, 1.0)\n",
    "            base_uncertainty = r.uniform(0.18, 0.32)\n",
    "        elif size == \"MEDIUM\":\n",
    "            base_scale = r.uniform(1.0, 1.35)\n",
    "            base_uncertainty = r.uniform(0.22, 0.40)\n",
    "        else:  # LARGE\n",
    "            base_scale = r.uniform(1.35, 1.75)\n",
    "            base_uncertainty = r.uniform(0.28, 0.55)\n",
    "\n",
    "        # Tail heaviness increases uncertainty\n",
    "        if profile[\"tail\"] == \"HEAVY_TAIL\":\n",
    "            base_uncertainty = min(0.65, base_uncertainty + 0.10)\n",
    "\n",
    "        # Burn rate and fixed cost (synthetic but realistic ranges)\n",
    "        burn_rate = float(r.uniform(1800, 6500))\n",
    "        fixed_cost = float(r.uniform(15000, 120000))\n",
    "\n",
    "        # Include build streams based on size\n",
    "        streams = included_streams(size, r)\n",
    "\n",
    "        # Build task set\n",
    "        task_defs = {code: (name, phase, w) for code, name, phase, w in BASE_TASK_LIBRARY}\n",
    "        included_tasks = [\"T_INIT\", \"T_REQ\", \"T_DES\", \"T_GOV\"] + streams + [\"T_INT\", \"T_DOC\", \"T_UAT\", \"T_SEC\", \"T_REM\", \"T_PRE\", \"T_PIL\", \"T_ROL\"]\n",
    "\n",
    "        # Set deps dynamically\n",
    "        deps = dict(BASE_DEPS)\n",
    "        deps[\"T_INT\"] = streams  # integrate waits for all streams\n",
    "        deps[\"T_UAT\"] = [\"T_INT\", \"T_DOC\"]\n",
    "\n",
    "        # Generate 3-point estimates per task\n",
    "        for tcode in included_tasks:\n",
    "            name, phase, weight = task_defs[tcode]\n",
    "            base_days = 6.0 * weight * base_scale  # base anchor\n",
    "            # Late-stage tasks tend to have more uncertainty in late-heavy projects\n",
    "            uncertainty = base_uncertainty\n",
    "            if profile[\"late_concentration\"] == \"LATE_HEAVY\" and phase in [\"SEC_TEST\", \"REMEDIATE\", \"PILOT\", \"ROLLOUT\"]:\n",
    "                uncertainty = min(0.70, uncertainty + 0.12)\n",
    "\n",
    "            o, m, p = triangular_params_from_scale(base_days, uncertainty, r)\n",
    "\n",
    "            tasks_rows.append({\n",
    "                \"project_id\": project_id,\n",
    "                \"task_code\": tcode,\n",
    "                \"task_name\": name,\n",
    "                \"phase\": phase,\n",
    "                \"opt_o\": o,\n",
    "                \"likely_m\": m,\n",
    "                \"pess_p\": p,\n",
    "                \"pred\": \";\".join(deps.get(tcode, [])),\n",
    "            })\n",
    "\n",
    "        # Risk probabilities based on risk_level bucket\n",
    "        rl = profile[\"risk_level\"]\n",
    "        col = {\"LOW\": 0, \"MED\": 1, \"HIGH\": 2, \"EXTREME\": 2}[rl]  # EXTREME uses \"high\" base probs but stronger impacts\n",
    "\n",
    "        for risk_id, rname, rtype, timing, p_low, p_med, p_high in RISK_LIBRARY:\n",
    "            p_base = [p_low, p_med, p_high][col]\n",
    "\n",
    "            # If late-heavy, increase late risk probabilities slightly\n",
    "            if profile[\"late_concentration\"] == \"LATE_HEAVY\" and timing == \"LATE\":\n",
    "                p_base = min(0.60, p_base + 0.06)\n",
    "\n",
    "            # If extreme tail, push late risks + impact magnitude\n",
    "            impact_multiplier = 1.0\n",
    "            if rl == \"EXTREME\" and timing == \"LATE\":\n",
    "                p_base = min(0.65, p_base + 0.08)\n",
    "                impact_multiplier = 1.35\n",
    "\n",
    "            # Define impact distributions (stored as parameters for Phase 2 engine)\n",
    "            # ADD risks: add triangular days; cost lump sum triangular\n",
    "            # MUL risks: multiply durations by lognormal factor; plus extra add-on days for testing\n",
    "            if rtype == \"ADD\":\n",
    "                # schedule add: triangular\n",
    "                add_o = 1.0 * impact_multiplier\n",
    "                add_m = 6.0 * impact_multiplier\n",
    "                add_p = 16.0 * impact_multiplier if timing != \"LATE\" else 24.0 * impact_multiplier\n",
    "\n",
    "                cost_o = 2000.0 * impact_multiplier\n",
    "                cost_m = 12000.0 * impact_multiplier\n",
    "                cost_p = 45000.0 * impact_multiplier if timing == \"LATE\" else 30000.0 * impact_multiplier\n",
    "\n",
    "                risks_rows.append({\n",
    "                    \"project_id\": project_id,\n",
    "                    \"risk_id\": risk_id,\n",
    "                    \"risk_name\": rname,\n",
    "                    \"risk_type\": \"ADD\",\n",
    "                    \"probability\": round(float(p_base), 4),\n",
    "                    \"targets\": \";\".join([t for t in RISK_TARGETS[risk_id] if t in included_tasks]),\n",
    "                    \"sched_add_tri_o\": round(add_o, 2),\n",
    "                    \"sched_add_tri_m\": round(add_m, 2),\n",
    "                    \"sched_add_tri_p\": round(add_p, 2),\n",
    "                    \"mul_logn_mu\": np.nan,\n",
    "                    \"mul_logn_sigma\": np.nan,\n",
    "                    \"cost_lump_tri_o\": round(cost_o, 2),\n",
    "                    \"cost_lump_tri_m\": round(cost_m, 2),\n",
    "                    \"cost_lump_tri_p\": round(cost_p, 2),\n",
    "                })\n",
    "\n",
    "            else:  # MUL (critical vulnerability)\n",
    "                # lognormal factor controls heaviness of rework\n",
    "                # EXTREME tail -> higher sigma\n",
    "                mu = 0.12 * impact_multiplier\n",
    "                sigma = 0.28 * impact_multiplier\n",
    "                if profile[\"tail\"] == \"HEAVY_TAIL\":\n",
    "                    sigma = min(0.85, sigma + 0.12)\n",
    "\n",
    "                # plus some additive days on SEC/REM in addition to multipliers\n",
    "                add_o = 1.0 * impact_multiplier\n",
    "                add_m = 5.0 * impact_multiplier\n",
    "                add_p = 18.0 * impact_multiplier\n",
    "\n",
    "                cost_o = 5000.0 * impact_multiplier\n",
    "                cost_m = 18000.0 * impact_multiplier\n",
    "                cost_p = 70000.0 * impact_multiplier if profile[\"tail\"] == \"HEAVY_TAIL\" else 45000.0 * impact_multiplier\n",
    "\n",
    "                risks_rows.append({\n",
    "                    \"project_id\": project_id,\n",
    "                    \"risk_id\": risk_id,\n",
    "                    \"risk_name\": rname,\n",
    "                    \"risk_type\": \"MUL\",\n",
    "                    \"probability\": round(float(p_base), 4),\n",
    "                    \"targets\": \";\".join([t for t in RISK_TARGETS[risk_id] if t in included_tasks]),\n",
    "                    \"sched_add_tri_o\": round(add_o, 2),\n",
    "                    \"sched_add_tri_m\": round(add_m, 2),\n",
    "                    \"sched_add_tri_p\": round(add_p, 2),\n",
    "                    \"mul_logn_mu\": round(float(mu), 4),\n",
    "                    \"mul_logn_sigma\": round(float(sigma), 4),\n",
    "                    \"cost_lump_tri_o\": round(cost_o, 2),\n",
    "                    \"cost_lump_tri_m\": round(cost_m, 2),\n",
    "                    \"cost_lump_tri_p\": round(cost_p, 2),\n",
    "                })\n",
    "\n",
    "        projects_rows.append({\n",
    "            \"project_id\": project_id,\n",
    "            \"size_bucket\": size,\n",
    "            \"risk_level_bucket\": rl,\n",
    "            \"late_concentration\": profile[\"late_concentration\"],\n",
    "            \"tail_type\": profile[\"tail\"],\n",
    "            \"coupling\": profile[\"coupling\"],\n",
    "            \"burn_rate_per_day\": round(burn_rate, 2),\n",
    "            \"fixed_cost\": round(fixed_cost, 2),\n",
    "            \"n_tasks\": len(included_tasks),\n",
    "            \"n_streams\": len(streams),\n",
    "        })\n",
    "\n",
    "    projects_df = pd.DataFrame(projects_rows)\n",
    "    tasks_df = pd.DataFrame(tasks_rows)\n",
    "    risks_df = pd.DataFrame(risks_rows)\n",
    "\n",
    "    return projects_df, tasks_df, risks_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef2f901b-a1b7-4eed-b995-501163dcf8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - synthetic_data\\projects.csv\n",
      " - synthetic_data\\tasks.csv\n",
      " - synthetic_data\\risks.csv\n",
      "\n",
      "Project bucket counts:\n",
      "risk_level_bucket  size_bucket\n",
      "EXTREME            LARGE          2\n",
      "                   MEDIUM         2\n",
      "                   SMALL          2\n",
      "HIGH               LARGE          2\n",
      "                   MEDIUM         2\n",
      "                   SMALL          2\n",
      "LOW                LARGE          2\n",
      "                   MEDIUM         2\n",
      "                   SMALL          2\n",
      "MED                LARGE          2\n",
      "                   MEDIUM         2\n",
      "                   SMALL          2\n",
      "dtype: int64\n",
      "\n",
      "Example tasks (first project):\n",
      "   task_code                               task_name  opt_o  likely_m  pess_p  \\\n",
      "0     T_INIT                      Project Initiation   4.12      5.05    6.05   \n",
      "1      T_REQ                  Requirements Gathering   5.89      7.11    8.61   \n",
      "2      T_DES          Solution Architecture & Design   5.02      5.93    7.13   \n",
      "3      T_GOV            Security Policy / Governance   3.89      4.98    6.12   \n",
      "4       T_BA            Core Implementation Stream A   9.70     11.47   14.18   \n",
      "5       T_BB                 Implementation Stream B   7.71      9.41   10.79   \n",
      "6      T_INT                     Systems Integration   6.06      7.04    8.13   \n",
      "7      T_DOC                Compliance Documentation   4.60      5.65    7.00   \n",
      "8      T_UAT                 User Acceptance Testing   5.25      6.32    7.56   \n",
      "9      T_SEC  Security Testing / Penetration Testing   4.98      6.65    8.84   \n",
      "10     T_REM               Vulnerability Remediation   4.20      6.19    8.16   \n",
      "11     T_PRE               Pre-Production Validation   4.79      5.82    6.82   \n",
      "12     T_PIL                        Pilot Deployment   4.07      5.82    7.41   \n",
      "13     T_ROL                 Full Production Rollout   3.21      4.70    5.91   \n",
      "\n",
      "           pred  \n",
      "0                \n",
      "1        T_INIT  \n",
      "2         T_REQ  \n",
      "3         T_DES  \n",
      "4   T_DES;T_GOV  \n",
      "5   T_DES;T_GOV  \n",
      "6     T_BA;T_BB  \n",
      "7         T_GOV  \n",
      "8   T_INT;T_DOC  \n",
      "9         T_UAT  \n",
      "10        T_SEC  \n",
      "11        T_REM  \n",
      "12        T_PRE  \n",
      "13        T_PIL  \n",
      "\n",
      "Example risks (first project):\n",
      "  risk_id  probability risk_type                 targets\n",
      "0  R_COMP         0.10       ADD             T_GOV;T_DOC\n",
      "1  R_VEND         0.15       ADD                   T_INT\n",
      "2  R_VULN         0.14       MUL  T_BA;T_INT;T_SEC;T_REM\n",
      "3  R_INCI         0.11       ADD             T_PIL;T_ROL\n"
     ]
    }
   ],
   "source": [
    "def save_outputs(cfg: GeneratorConfig, projects_df: pd.DataFrame, tasks_df: pd.DataFrame, risks_df: pd.DataFrame) -> None:\n",
    "    import os\n",
    "    os.makedirs(cfg.out_dir, exist_ok=True)\n",
    "\n",
    "    projects_path = os.path.join(cfg.out_dir, \"projects.csv\")\n",
    "    tasks_path = os.path.join(cfg.out_dir, \"tasks.csv\")\n",
    "    risks_path = os.path.join(cfg.out_dir, \"risks.csv\")\n",
    "\n",
    "    projects_df.to_csv(projects_path, index=False)\n",
    "    tasks_df.to_csv(tasks_path, index=False)\n",
    "    risks_df.to_csv(risks_path, index=False)\n",
    "\n",
    "    print(\"Saved:\")\n",
    "    print(\" -\", projects_path)\n",
    "    print(\" -\", tasks_path)\n",
    "    print(\" -\", risks_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = GeneratorConfig(n_projects=24, seed=42, out_dir=\"synthetic_data\")\n",
    "    projects_df, tasks_df, risks_df = generate_projects(cfg)\n",
    "    save_outputs(cfg, projects_df, tasks_df, risks_df)\n",
    "\n",
    "    # quick sanity summaries\n",
    "    print(\"\\nProject bucket counts:\")\n",
    "    print(projects_df.groupby([\"risk_level_bucket\", \"size_bucket\"]).size().sort_values(ascending=False).head(12))\n",
    "\n",
    "    print(\"\\nExample tasks (first project):\")\n",
    "    print(tasks_df[tasks_df[\"project_id\"] == \"P01\"][[\"task_code\",\"task_name\",\"opt_o\",\"likely_m\",\"pess_p\",\"pred\"]])\n",
    "\n",
    "    print(\"\\nExample risks (first project):\")\n",
    "    print(risks_df[risks_df[\"project_id\"] == \"P01\"][[\"risk_id\",\"probability\",\"risk_type\",\"targets\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Environment1]",
   "language": "python",
   "name": "conda-env-Environment1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
